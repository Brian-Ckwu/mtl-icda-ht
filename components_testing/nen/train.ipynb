{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import sys\n",
    "sys.path.append(\"/nfs/nas-7.1/ckwu/mtl-icda-ht\")\n",
    "\n",
    "import json\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from argparse import Namespace\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from data import BertNENDataset, KBEntities\n",
    "from model import BiEncoder\n",
    "from test import fullset_evaluate\n",
    "from utilities.data import split_by_div\n",
    "from utilities.model import encoder_names_mapping\n",
    "from utilities.utils import set_seeds, render_exp_name, move_bert_input_to_device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = json.loads(Path(\"./config.json\").read_bytes())\n",
    "# args = Namespace(**config)\n",
    "\n",
    "# args.save_dir = Path(args.save_dir)\n",
    "# args.exp_name = render_exp_name(args, hparams=[\"encoder\", \"seed\", \"emrbs\", \"cuibs\", \"optimizer\", \"lr\", \"nepochs\", \"fold\", \"remainder\"])\n",
    "# args.ckpt_path = args.save_dir / args.exp_name\n",
    "# args.ckpt_path.mkdir(parents=True, exist_ok=True)\n",
    "# (args.ckpt_path / \"args.pickle\").write_bytes(pickle.dumps(args))\n",
    "\n",
    "# Load args of trained model\n",
    "args = pickle.loads(Path(\"/nfs/nas-7.1/ckwu/mtl-icda-ht/components_testing/nen/models/encoder-BERT_seed-42_emrbs-1_cuibs-16_optimizer-Adam_lr-1e-05_nepochs-5_fold-10_remainder-0/args.pickle\").read_bytes())\n",
    "\n",
    "set_seeds(args.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emrs = pickle.loads(Path(args.emr_path).read_bytes())\n",
    "ner_spans_l = pickle.loads(Path(args.ner_spans_l_path).read_bytes())\n",
    "sm2cui = json.loads(Path(args.sm2cui_path).read_bytes())\n",
    "smcui2name = json.loads(Path(args.smcui2name_path).read_bytes())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train / Valid Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_emrs, train_ner_spans_l = [split_by_div(data, fold=args.fold, remainder=args.remainder, mode=\"train\") for data in [emrs, ner_spans_l]]\n",
    "valid_emrs, valid_ner_spans_l = [split_by_div(data, fold=args.fold, remainder=args.remainder, mode=\"valid\") for data in [emrs, ner_spans_l]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct Dataset & DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(encoder_names_mapping[args.tokenizer])\n",
    "\n",
    "train_set = BertNENDataset(\n",
    "    emrs=train_emrs,\n",
    "    ner_spans_l=train_ner_spans_l,\n",
    "    mention2cui=sm2cui,\n",
    "    cui2name=smcui2name,\n",
    "    cui_batch_size=args.cuibs,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "valid_set = BertNENDataset(\n",
    "    emrs=valid_emrs,\n",
    "    ner_spans_l=valid_ner_spans_l,\n",
    "    mention2cui=sm2cui,\n",
    "    cui2name=smcui2name,\n",
    "    cui_batch_size=args.cuibs,\n",
    "    tokenizer=tokenizer    \n",
    ")\n",
    "entities_set = KBEntities(\n",
    "    id2desc=smcui2name,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=args.emrbs, shuffle=True, pin_memory=True, collate_fn=lambda batch: batch[0])\n",
    "valid_loader = DataLoader(valid_set, batch_size=args.emrbs, shuffle=False, pin_memory=True, collate_fn=lambda batch: batch[0])\n",
    "entities_loader = DataLoader(entities_set, batch_size=args.cuibs, shuffle=False, pin_memory=True, collate_fn=entities_set.collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model, Optimizer, and Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BiEncoder(encoder_name=encoder_names_mapping[args.encoder]).to(args.device)\n",
    "# optimizer = getattr(torch.optim, args.optimizer)(model.parameters(), lr=args.lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsteps = 0\n",
    "stale = 0\n",
    "best_fullset_acc = 0.0\n",
    "\n",
    "for epoch in range(1, args.nepochs + 1):\n",
    "    print(f\"\\n===== Start training at epoch {epoch} =====\\n\")\n",
    "    pbar = tqdm(total=len(train_loader), ncols=0, desc=\"Train\", unit=\" steps\")\n",
    "\n",
    "    for emr_be, mention_indices_l, target_cuis, negative_cuis_l in train_loader:\n",
    "        model.train()\n",
    "        \n",
    "        # Encode mentions\n",
    "        emr_be = move_bert_input_to_device(emr_be, args.device)\n",
    "\n",
    "        mentions = model.encode_mentions(emr_be, mention_indices_l)\n",
    "        assert len(mentions) == len(mention_indices_l) == len(target_cuis) == len(negative_cuis_l)\n",
    "\n",
    "        # Encode entities\n",
    "        emr_loss = torch.tensor([0.0]).to(args.device)\n",
    "        for mention, target_cui, negative_cuis in zip(mentions, target_cuis, negative_cuis_l):\n",
    "            batch_cuis = [target_cui] + negative_cuis; assert len(batch_cuis) == args.cuibs\n",
    "            ents_be = train_set.make_entities_be(cuis=batch_cuis).to(args.device)\n",
    "            ents_labels = train_set.make_entities_labels(target_cui, negative_cuis).to(args.device)\n",
    "\n",
    "            y_ment = mention\n",
    "            y_ents = model.encode_entities(ents_be)\n",
    "\n",
    "            # Calculate score & loss\n",
    "            scores = model.calc_scores(y_ment, y_ents)\n",
    "            loss = model.calc_loss(scores.squeeze(), ents_labels)\n",
    "\n",
    "            # Accumulate loss\n",
    "            emr_loss += loss\n",
    "        \n",
    "        # Update parameters\n",
    "        optimizer.zero_grad()\n",
    "        if emr_loss.requires_grad:\n",
    "            emr_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Evaluate every k steps\n",
    "        if nsteps % args.ckpt_steps == 0:\n",
    "            fullset_acc = fullset_evaluate(valid_loader, model, args, entities_loader=entities_loader)\n",
    "            print(f\"Model evaluated at step {nsteps}: accuracy = {fullset_acc:.3f}\")\n",
    "            if fullset_acc > best_fullset_acc:\n",
    "                stale = 0\n",
    "                best_fullset_acc = fullset_acc\n",
    "                print(\"Saving best model.\")\n",
    "                torch.save(model.state_dict(), args.ckpt_path / \"best_model.ckpt\")\n",
    "            else:\n",
    "                stale += 1\n",
    "                print(f\"Model stop improving for {int(stale * args.ckpt_steps)} steps.\")\n",
    "                if stale >= args.patience:\n",
    "                    print(\"Stop training because of early stopping.\")\n",
    "\n",
    "\n",
    "        mean_loss = (emr_loss.detach().cpu().item() / len(mentions)) if len(mentions) > 0 else emr_loss.detach().cpu().item()\n",
    "        nsteps += 1\n",
    "        pbar.update(n=1)\n",
    "        pbar.set_postfix(\n",
    "            loss=f\"{mean_loss:.3f}\",\n",
    "            acc=f\"{fullset_acc:.3f}\",\n",
    "            steps=nsteps\n",
    "        )\n",
    "\n",
    "        del emr_loss, mean_loss\n",
    "        gc.collect()\n",
    "\n",
    "    pbar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained model\n",
    "model.load_state_dict(torch.load(args.ckpt_path / \"best_model.ckpt\"))\n",
    "model.eval()\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_embeddings = torch.load(args.ckpt_path / \"entity_embeddings_5454.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Set Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullset_acc, batch_exec_times = fullset_evaluate(valid_loader, model, args, entity_embeddings, entities_loader=entities_loader)\n",
    "fullset_acc, sum(batch_exec_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution Time Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "bets = np.array(batch_exec_times)\n",
    "\n",
    "bets.mean(), bets.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "sns.histplot(data=bets, stat=\"density\", kde=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qualitative Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List\n",
    "\n",
    "# Variables\n",
    "data_loader = valid_loader\n",
    "all_y_ents = entity_embeddings.to(args.device)\n",
    "all_cuis = entities_set._ids\n",
    "all_descs = entities_set._descs\n",
    "\n",
    "# Evaluation\n",
    "# quantitative\n",
    "total_correct = 0\n",
    "total_predict = 0\n",
    "# qualitative\n",
    "ment2ent_count: Dict[str, Dict[str, int]] = dict()\n",
    "ent2ment_count: Dict[str, Dict[str, int]] = dict()\n",
    "\n",
    "def update_dicts(\n",
    "        ment2ent: Dict[str, Dict[str, int]],\n",
    "        ent2ment: Dict[str, Dict[str, int]], \n",
    "        mention_surfs: List[str],\n",
    "        pred_descs: List[str]\n",
    "    ) -> None:\n",
    "    assert len(mention_surfs) == len(pred_descs)\n",
    "\n",
    "    for mention_surf, pred_desc in zip(mention_surfs, pred_descs):\n",
    "        ment = mention_surf\n",
    "        ent = pred_desc\n",
    "        \n",
    "        if ment not in ment2ent:\n",
    "            ment2ent[ment] = dict()\n",
    "        if ent not in ent2ment:\n",
    "            ent2ment[ent] = dict()\n",
    "        \n",
    "        ment2ent[ment][ent] = ment2ent[ment].get(ent, 0) + 1\n",
    "        ent2ment[ent][ment] = ent2ment[ent].get(ment, 0) + 1\n",
    "\n",
    "    return None\n",
    "\n",
    "model.eval()\n",
    "for emr_be, mention_indices_l, target_cuis, _ in data_loader: # No need of negative_cuis_l\n",
    "    # get surface forms of mentions\n",
    "    mention_ids_l = [emr_be[\"input_ids\"][0][mention_indices] for mention_indices in mention_indices_l] # mention token IDs\n",
    "    mention_surfs = [tokenizer.decode(mention_ids) for mention_ids in mention_ids_l] # mention surface forms\n",
    "\n",
    "    pred_descs = list()\n",
    "    with torch.no_grad():\n",
    "        emr_be = move_bert_input_to_device(emr_be, args.device)\n",
    "        y_ments = model.encode_mentions(emr_be, mention_indices_l)\n",
    "        assert len(y_ments) == len(mention_indices_l) == len(target_cuis)\n",
    "\n",
    "        scores = model.calc_scores(y_ments, all_y_ents)\n",
    "\n",
    "        preds = scores.argmax(dim=-1).cpu().tolist()\n",
    "        \n",
    "        for pred, target_cui in zip(preds, target_cuis):\n",
    "            pred_cui = all_cuis[pred]\n",
    "            pred_desc = all_descs[pred]\n",
    "            pred_descs.append(pred_desc)\n",
    "\n",
    "            if pred_cui == target_cui:\n",
    "                total_correct += 1\n",
    "        \n",
    "        total_predict += len(preds)\n",
    "    \n",
    "    # Update stats of 2 dicts\n",
    "    update_dicts(ment2ent_count, ent2ment_count, mention_surfs, pred_descs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2e_path = Path(args.ckpt_path / \"ment2ent_count.json\")\n",
    "m2e_path.write_text(json.dumps(ment2ent_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e2m_path = Path(args.ckpt_path / \"ent2ment_count.json\")\n",
    "e2m_path.write_text(json.dumps(ent2ment_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Previous Evaluation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "untrained_bert_fullset_acc = 0.001633605600933489\n",
    "untrained_linkbert_fullset_acc = 0.00023380874444704232\n",
    "untrained_biobert_fullset_acc = 0.11421557166238017\n",
    "untrained_clinicalbert_fullset_acc = 0.0911854103343465\n",
    "trained_bert_fullset_acc = 0.8989498249708284"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "untrained_bert_loss, untrained_bert_acc = (17.59189080480663, 0.1294049008168028)\n",
    "untrained_biobert_loss, untrained_biobert_acc = (86.79308684462555, 0.7194295066635492)\n",
    "untrained_clinicalbert_loss, untrained_clinicalbert_acc = (103.7931861654464, 0.6738368014963759)\n",
    "trained_loss, trained_acc = (0.010365398921037055, 0.9957992998833138)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d36bacadd0665529eea11cf0e685dbe0df5591baeef20597c1b063990f001dc3"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
