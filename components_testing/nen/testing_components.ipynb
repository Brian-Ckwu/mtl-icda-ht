{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import BertTokenizerFast\n",
    "\n",
    "from data import BertNENDataset\n",
    "from model import BiEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load EMRs\n",
    "\n",
    "emrs_path = Path(\"/nfs/nas-7.1/ckwu/datasets/emr/6000/emrs_with_annots.pickle\")\n",
    "emrs = pickle.loads(emrs_path.read_bytes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load NER spans tuples\n",
    "\n",
    "ner_spans_tuples = Path(\"/nfs/nas-7.1/ckwu/datasets/emr/6000/ner_spans_tuples.pickle\")\n",
    "ner_spans_l = pickle.loads(ner_spans_tuples.read_bytes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Mention to CUI\n",
    "\n",
    "sm2cui_path = Path(\"/nfs/nas-7.1/ckwu/datasets/nen/data/single_mention2cui.json\")\n",
    "sm2cui = json.loads(sm2cui_path.read_bytes())\n",
    "\n",
    "# Load CUI to preferred name\n",
    "smcui2name_path = Path(\"/nfs/nas-7.1/ckwu/datasets/umls/smcui2name.json\")\n",
    "cui2name = json.loads(smcui2name_path.read_bytes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "dataset = BertNENDataset(emrs, ner_spans_l, sm2cui, cui2name, cui_batch_size=16, tokenizer=tokenizer)\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True, pin_memory=True, collate_fn=lambda batch: batch[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = next(iter(dataloader))\n",
    "emr_be, token_indices_l, cuis, negative_cuis_l = sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cui_idx = 8\n",
    "\n",
    "cui = cuis[cui_idx]\n",
    "negative_cuis = negative_cuis_l[cui_idx]\n",
    "\n",
    "ents_be = dataset.make_entities_be(cuis=[cui] + negative_cuis)\n",
    "ents_labels = dataset.make_entities_labels(target_cui=cui, negative_cuis=negative_cuis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BiEncoder(encoder_name=\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ents = model.encode_entities(ents_be)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mentions = model.encode_mentions(emr_be, token_indices_l)\n",
    "assert len(mentions) == len(token_indices_l) == len(cuis) == len(negative_cuis_l)\n",
    "y_ment = mentions[cui_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.calc_scores(y_ment, y_ents)\n",
    "loss = model.calc_loss(scores.squeeze(), ents_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emr_idx = 1\n",
    "\n",
    "emr = emrs[emr_idx]\n",
    "spans = spans_tuples[emr_idx]\n",
    "be = tokenizer(emr, return_offsets_mapping=True)\n",
    "offsets = be.pop(\"offset_mapping\")\n",
    "token_indices_l = spans_to_token_indices_l(spans, offsets)\n",
    "\n",
    "for token_indices in token_indices_l:\n",
    "    mention = tokenizer.decode([be[\"input_ids\"][token_idx] for token_idx in token_indices])\n",
    "    print(mention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mentions = model.encode_mentions(be.convert_to_tensors(\"pt\", prepend_batch_axis=True), token_indices_l)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d36bacadd0665529eea11cf0e685dbe0df5591baeef20597c1b063990f001dc3"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
