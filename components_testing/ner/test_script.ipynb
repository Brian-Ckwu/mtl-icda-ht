{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import sys\n",
    "sys.path.append(\"/nfs/nas-7.1/ckwu/mtl-icda-ht\")\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import json\n",
    "import pickle\n",
    "import gc\n",
    "\n",
    "from argparse import Namespace\n",
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from utilities.data import MedicalNERIOBDataset, split_by_div\n",
    "from utilities.utils import set_seeds, load_config, render_exp_name, move_bert_input_to_device\n",
    "from utilities.model import BertNERModel, encoder_names_mapping\n",
    "from utilities.evaluation import visualize_iobpol_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config()\n",
    "args = Namespace(**config)\n",
    "hparams = [\"encoder\", \"optimizer\", \"lr\", \"nepochs\", \"bs\", \"fold\", \"remainder\"]\n",
    "assert args.bs % args.grad_accum_steps == 0\n",
    "\n",
    "args.exp_name = render_exp_name(args, hparams)\n",
    "args.ckpt_path = Path(args.save_dir) / args.exp_name\n",
    "args.ckpt_path.mkdir(parents=True, exist_ok=True)\n",
    "(args.ckpt_path / \"args.pickle\").write_bytes(pickle.dumps(args))\n",
    "\n",
    "set_seeds(args.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emrs = pickle.loads(Path(args.emr_path).read_bytes())\n",
    "ner_spans_l = pickle.loads(Path(args.ner_spans_l_path).read_bytes())\n",
    "\n",
    "train_emrs, train_labels = [split_by_div(data, fold=args.fold, remainder=args.remainder, mode=\"train\") for data in [emrs, ner_spans_l]]\n",
    "valid_emrs, valid_labels = [split_by_div(data, fold=args.fold, remainder=args.remainder, mode=\"valid\") for data in [emrs, ner_spans_l]]\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(encoder_names_mapping[args.encoder], use_fast=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Developing IOB with Polarity Label Mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Correctness of bert_offsets_to_iob_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = MedicalIOBPOLDataset(\n",
    "    text_l=train_emrs,\n",
    "    ner_spans_l=train_labels,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "valid_set = MedicalIOBPOLDataset(\n",
    "    text_l=valid_emrs,\n",
    "    ner_spans_l=valid_labels,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from colorama import Fore, Style\n",
    "\n",
    "label_color_mappings = {\n",
    "    0: Style.RESET_ALL,\n",
    "    1: Fore.GREEN,\n",
    "    2: Fore.CYAN,\n",
    "    3: Fore.RED,\n",
    "    4: Fore.YELLOW,\n",
    "    -100: Style.RESET_ALL\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emr_idx = 12\n",
    "text_be, iob_labels = valid_set[emr_idx]\n",
    "\n",
    "visualize_iobpol_labels(tokenizer, text_be[\"input_ids\"].tolist(), iob_labels, label_color_mappings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, batch_size=args.bs, shuffle=True, pin_memory=True, collate_fn=train_set.collate_fn)\n",
    "valid_loader = DataLoader(valid_set, batch_size=args.bs, shuffle=False, pin_memory=True, collate_fn=valid_set.collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "model = BertNERModel(encoder=encoder_names_mapping[args.encoder], num_tags=train_set.num_tags).to(args.device)\n",
    "model.load_state_dict(torch.load(\"/nfs/nas-7.1/ckwu/mtl-icda-ht/components_testing/ner/models/encoder-BioBERT_nepochs-5_bs-16_lr-4e-05_fold-10_remainder-0.pth\", map_location=args.device))\n",
    "# criterion = nn.CrossEntropyLoss(reduction=\"mean\", ignore_index=-100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record = trainer(train_loader, valid_loader, model, criterion, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save evaluation results\n",
    "with open(\"./eval_results/{}.json\".format(config[\"model_save_name\"]), \"wt\") as f:\n",
    "    json.dump(record, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(valid_loader))\n",
    "x = move_bert_input_to_device(x, args.device)\n",
    "y = y.to(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 9\n",
    "\n",
    "input_ids = x[\"input_ids\"][idx].tolist()\n",
    "label_ids = scores.argmax(dim=-1)[idx].tolist()\n",
    "\n",
    "visualize_iob_labels(tokenizer, input_ids, label_ids, train_set.idx2iob)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d36bacadd0665529eea11cf0e685dbe0df5591baeef20597c1b063990f001dc3"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
